{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ba2e5d-4804-4c34-b477-e24e09380591",
   "metadata": {},
   "source": [
    "# INCOME PREDICTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f947fc-6008-4431-a8a4-920a712a5eb1",
   "metadata": {},
   "source": [
    "RISHANA SHERIN T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f53e39-51fb-4c59-a840-5cf108ab1bed",
   "metadata": {},
   "source": [
    "ENTRI ELEVATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0fa00e-eafd-446e-b6c6-c10de88c3124",
   "metadata": {},
   "source": [
    "### OVERVIEW OF PROBLEM STATEMENT:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bb017-d4a3-4b96-b3f4-2a16ccbafd4f",
   "metadata": {},
   "source": [
    "The dataset consists of 42 columns and 42,285 rows. It contains both categorical and numerical features related to demographics, employment, and income."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96397aea-5579-4524-a50e-633eaff485e1",
   "metadata": {},
   "source": [
    "### OBJECTIVE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ca499-fd8f-48e3-be21-a9019c551afa",
   "metadata": {},
   "source": [
    "The goal of this analysis is to explore and process the dataset to derive meaningful insights and build a predictive model.The focus is to predict income levels or understanding employment trends based on demographic and occupational attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5434b8-0856-4600-babf-50ec98968858",
   "metadata": {},
   "source": [
    "### DATA DESCRIPTION:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ae48ca-c5bf-4efb-bf67-fbb3bf579e70",
   "metadata": {},
   "source": [
    "Source: UCI machine learning repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba9397-a26d-4987-82f4-1af6f869c88f",
   "metadata": {},
   "source": [
    "-Numerical Columns (e.g., Age, Occupation Code, Capital Gains, Weeks Worked in Year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de607aea-95d1-42d1-9159-f248c486bb72",
   "metadata": {},
   "source": [
    "-Categorical Columns (e.g., Class of Worker, Education, Race, Marital Status, Sex, Citizenship)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7099db24-9f30-4103-8704-47e610cb0ab4",
   "metadata": {},
   "source": [
    "-Potential Target Variable: The column labeled \"income\"is the target for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d802d6-cec2-4158-bc65-f9c24e8cadff",
   "metadata": {},
   "source": [
    "## DATA COLLECTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60746ee-06f1-46b0-a0d7-02130d4e84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('output_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de375309-0fb1-4f95-b885-a4d037b454cc",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01d56cc0-5ecc-485a-8445-23b0d4928711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved as: your_output_file.csv\n"
     ]
    }
   ],
   "source": [
    "column_names = [\n",
    "    'age', 'class of worker', 'industry code', 'occupation code', 'education', 'enrolled in edu last week', \n",
    "    'marital status', 'major industry code', 'major occupation code', 'race', 'hispanic origin', 'sex', \n",
    "    'member of a labor union', 'reason for unemployment', 'full or part time employment stat', 'capital gains', \n",
    "    'capital losses', 'dividends from stocks', 'tax filer status', 'region of previous residence', \n",
    "    'state of previous residence', 'detailed household and family stat', \n",
    "    'detailed household summary in household', 'instance weight', 'migration code-change in msa', \n",
    "    'migration code-change in reg', 'migration code-move within reg', 'live in this house 1 year ago', \n",
    "    'migration prev res in sunbelt', 'num persons worked for employer', 'family members under 18', \n",
    "    'country of birth father', 'country of birth mother', 'country of birth self', 'citizenship', \n",
    "    'own business or self employed', \"fill inc questionaire for veteran's admin\", 'veterans benefits', \n",
    "    'weeks worked in year', 'income', 'wage per hour', 'year'\n",
    "]\n",
    "\n",
    "df.columns = column_names\n",
    "\n",
    "# Save the updated file\n",
    "updated_file_path = \"your_output_file.csv\" \n",
    "df.to_csv(updated_file_path, index=False)\n",
    "\n",
    "print(f\"Updated file saved as: {updated_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c11956-02fb-4f1e-ba11-30cea39ef610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42284 entries, 0 to 42283\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   age                                        42284 non-null  int64  \n",
      " 1   class of worker                            42284 non-null  object \n",
      " 2   industry code                              42284 non-null  int64  \n",
      " 3   occupation code                            42284 non-null  int64  \n",
      " 4   education                                  42284 non-null  object \n",
      " 5   enrolled in edu last week                  42284 non-null  int64  \n",
      " 6   marital status                             42284 non-null  object \n",
      " 7   major industry code                        42284 non-null  object \n",
      " 8   major occupation code                      42284 non-null  object \n",
      " 9   race                                       42284 non-null  object \n",
      " 10  hispanic origin                            42284 non-null  object \n",
      " 11  sex                                        42284 non-null  object \n",
      " 12  member of a labor union                    42284 non-null  object \n",
      " 13  reason for unemployment                    42284 non-null  object \n",
      " 14  full or part time employment stat          42284 non-null  object \n",
      " 15  capital gains                              42284 non-null  object \n",
      " 16  capital losses                             42284 non-null  int64  \n",
      " 17  dividends from stocks                      42284 non-null  int64  \n",
      " 18  tax filer status                           42284 non-null  int64  \n",
      " 19  region of previous residence               42284 non-null  object \n",
      " 20  state of previous residence                42284 non-null  object \n",
      " 21  detailed household and family stat         42284 non-null  object \n",
      " 22  detailed household summary in household    42284 non-null  object \n",
      " 23  instance weight                            42284 non-null  object \n",
      " 24  migration code-change in msa               42284 non-null  float64\n",
      " 25  migration code-change in reg               42284 non-null  object \n",
      " 26  migration code-move within reg             42284 non-null  object \n",
      " 27  live in this house 1 year ago              42284 non-null  object \n",
      " 28  migration prev res in sunbelt              42284 non-null  object \n",
      " 29  num persons worked for employer            42284 non-null  object \n",
      " 30  family members under 18                    42284 non-null  int64  \n",
      " 31  country of birth father                    42284 non-null  object \n",
      " 32  country of birth mother                    42284 non-null  object \n",
      " 33  country of birth self                      42284 non-null  object \n",
      " 34  citizenship                                42284 non-null  object \n",
      " 35  own business or self employed              42284 non-null  object \n",
      " 36  fill inc questionaire for veteran's admin  42283 non-null  float64\n",
      " 37  veterans benefits                          42283 non-null  object \n",
      " 38  weeks worked in year                       42283 non-null  float64\n",
      " 39  income                                     42283 non-null  float64\n",
      " 40  wage per hour                              42283 non-null  float64\n",
      " 41  year                                       42283 non-null  object \n",
      "dtypes: float64(5), int64(8), object(29)\n",
      "memory usage: 13.5+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d598c9e6-abe6-45ff-827b-bc7ea4db0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e9e40b-30ed-481a-bf42-62c471e6b53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42284 entries, 0 to 42283\n",
      "Data columns (total 42 columns):\n",
      " #   Column                                     Non-Null Count  Dtype  \n",
      "---  ------                                     --------------  -----  \n",
      " 0   age                                        42284 non-null  int64  \n",
      " 1   class of worker                            42284 non-null  object \n",
      " 2   industry code                              42284 non-null  int64  \n",
      " 3   occupation code                            42284 non-null  int64  \n",
      " 4   education                                  42284 non-null  object \n",
      " 5   enrolled in edu last week                  42284 non-null  int64  \n",
      " 6   marital status                             42284 non-null  object \n",
      " 7   major industry code                        42284 non-null  object \n",
      " 8   major occupation code                      42284 non-null  object \n",
      " 9   race                                       42284 non-null  object \n",
      " 10  hispanic origin                            42284 non-null  object \n",
      " 11  sex                                        42284 non-null  object \n",
      " 12  member of a labor union                    42284 non-null  object \n",
      " 13  reason for unemployment                    42284 non-null  object \n",
      " 14  full or part time employment stat          42284 non-null  object \n",
      " 15  capital gains                              42284 non-null  object \n",
      " 16  capital losses                             42284 non-null  int64  \n",
      " 17  dividends from stocks                      42284 non-null  int64  \n",
      " 18  tax filer status                           42284 non-null  int64  \n",
      " 19  region of previous residence               42284 non-null  object \n",
      " 20  state of previous residence                42284 non-null  object \n",
      " 21  detailed household and family stat         42284 non-null  object \n",
      " 22  detailed household summary in household    42284 non-null  object \n",
      " 23  instance weight                            42284 non-null  object \n",
      " 24  migration code-change in msa               42284 non-null  float64\n",
      " 25  migration code-change in reg               42284 non-null  object \n",
      " 26  migration code-move within reg             42284 non-null  object \n",
      " 27  live in this house 1 year ago              42284 non-null  object \n",
      " 28  migration prev res in sunbelt              42284 non-null  object \n",
      " 29  num persons worked for employer            42284 non-null  object \n",
      " 30  family members under 18                    42284 non-null  int64  \n",
      " 31  country of birth father                    42284 non-null  object \n",
      " 32  country of birth mother                    42284 non-null  object \n",
      " 33  country of birth self                      42284 non-null  object \n",
      " 34  citizenship                                42284 non-null  object \n",
      " 35  own business or self employed              42284 non-null  object \n",
      " 36  fill inc questionaire for veteran's admin  42283 non-null  float64\n",
      " 37  veterans benefits                          42283 non-null  object \n",
      " 38  weeks worked in year                       42283 non-null  float64\n",
      " 39  income                                     42283 non-null  float64\n",
      " 40  wage per hour                              42283 non-null  float64\n",
      " 41  year                                       42283 non-null  object \n",
      "dtypes: float64(5), int64(8), object(29)\n",
      "memory usage: 13.5+ MB\n",
      "\n",
      "Missing Values:\n",
      "age                                          0\n",
      "class of worker                              0\n",
      "industry code                                0\n",
      "occupation code                              0\n",
      "education                                    0\n",
      "enrolled in edu last week                    0\n",
      "marital status                               0\n",
      "major industry code                          0\n",
      "major occupation code                        0\n",
      "race                                         0\n",
      "hispanic origin                              0\n",
      "sex                                          0\n",
      "member of a labor union                      0\n",
      "reason for unemployment                      0\n",
      "full or part time employment stat            0\n",
      "capital gains                                0\n",
      "capital losses                               0\n",
      "dividends from stocks                        0\n",
      "tax filer status                             0\n",
      "region of previous residence                 0\n",
      "state of previous residence                  0\n",
      "detailed household and family stat           0\n",
      "detailed household summary in household      0\n",
      "instance weight                              0\n",
      "migration code-change in msa                 0\n",
      "migration code-change in reg                 0\n",
      "migration code-move within reg               0\n",
      "live in this house 1 year ago                0\n",
      "migration prev res in sunbelt                0\n",
      "num persons worked for employer              0\n",
      "family members under 18                      0\n",
      "country of birth father                      0\n",
      "country of birth mother                      0\n",
      "country of birth self                        0\n",
      "citizenship                                  0\n",
      "own business or self employed                0\n",
      "fill inc questionaire for veteran's admin    1\n",
      "veterans benefits                            1\n",
      "weeks worked in year                         1\n",
      "income                                       1\n",
      "wage per hour                                1\n",
      "year                                         1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display basic info\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "df.fillna(df.mode().iloc[0], inplace=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a66d4a-155f-4b86-89bf-c9b94faf4966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46577b02-5dd9-4cce-95f1-d112629af385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique values in categorical columns\n",
    "print(\"\\nUnique Values in Each Column:\")\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c05c46-812a-4748-a94f-0912c215ccb6",
   "metadata": {},
   "source": [
    "### Detect outliers using IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbf24278-76df-4e4d-8222-06bb7cd1d694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outliers Detection using IQR:\n",
      "age                                              0\n",
      "industry code                                    0\n",
      "occupation code                                  0\n",
      "enrolled in edu last week                     2395\n",
      "capital losses                                1632\n",
      "dividends from stocks                          819\n",
      "tax filer status                              4518\n",
      "migration code-change in msa                  1315\n",
      "family members under 18                          0\n",
      "fill inc questionaire for veteran's admin     4016\n",
      "weeks worked in year                         10420\n",
      "income                                           0\n",
      "wage per hour                                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOutliers Detection using IQR:\")\n",
    "def detect_outliers(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).sum()\n",
    "    return outliers\n",
    "\n",
    "outliers = detect_outliers(df.select_dtypes(include=['number']))\n",
    "print(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f2e29-2dd6-4a07-b670-915c1d5b7f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots to visualize outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "df.select_dtypes(include=['number']).boxplot(rot=90)\n",
    "plt.title(\"Boxplot of Numerical Features (Outliers Detection)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f8a33-1f1c-45fa-9a6b-ebb4625fbc0d",
   "metadata": {},
   "source": [
    "### Capping outliers using IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e3bfa1d-4b86-47f6-b17f-7f32c64b21d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outliers capped using IQR method. New dataset shape: (42284, 13)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def cap_outliers(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df.clip(lower=lower_bound, upper=upper_bound, axis=1)\n",
    "\n",
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "df_numeric = cap_outliers(df_numeric)\n",
    "print(\"\\nOutliers capped using IQR method. New dataset shape:\", df_numeric.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5de0cf-3497-4e9d-bc8a-17e6f1296d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots to visualize the cleaned dataset after capping outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_numeric)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Boxplot of Cleaned Numeric Features After Capping Outliers\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd45351-0db5-4404-b019-c018df7098ea",
   "metadata": {},
   "source": [
    "### compute and remove skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ea0e06-6698-4c34-a51b-815932f88838",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "could not convert string to float: ' Self-employed-not incorporated'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:85\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:477\u001b[0m, in \u001b[0;36mmaybe_operate_rowwise.<locals>.newfunc\u001b[1;34m(values, axis, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(results)\n\u001b[1;32m--> 477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(values, axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1240\u001b[0m, in \u001b[0;36mnanskew\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1240\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1241\u001b[0m     count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ' Self-employed-not incorporated'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m skewed_cols \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mskew()\u001b[38;5;241m.\u001b[39mabs() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m      2\u001b[0m df[skewed_cols\u001b[38;5;241m.\u001b[39mindex] \u001b[38;5;241m=\u001b[39m df[skewed_cols\u001b[38;5;241m.\u001b[39mindex]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mlog1p(x) \u001b[38;5;28;01mif\u001b[39;00m skewed_cols\u001b[38;5;241m.\u001b[39mloc[x\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;28;01melse\u001b[39;00m x)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11761\u001b[0m, in \u001b[0;36mDataFrame.skew\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11753\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskew\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11754\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mskew\u001b[39m(\n\u001b[0;32m  11755\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11759\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11760\u001b[0m ):\n\u001b[1;32m> 11761\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mskew(axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  11762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11763\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskew\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12442\u001b[0m, in \u001b[0;36mNDFrame.skew\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mskew\u001b[39m(\n\u001b[0;32m  12436\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12437\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12440\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12441\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12443\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskew\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanskew, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12444\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  12378\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  12379\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11562\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11558\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  11560\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11561\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11562\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[0;32m  11563\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  11564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1500\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1498\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1500\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[0;32m   1501\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1503\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:404\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    407\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11481\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[0;32m  11480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:92\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m---> 92\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: could not convert string to float: ' Self-employed-not incorporated'"
     ]
    }
   ],
   "source": [
    "    skewed_cols = df.skew().abs() > 0.5\n",
    "    df[skewed_cols.index] = df[skewed_cols.index].apply(lambda x: np.log1p(x) if skewed_cols.loc[x.name] else x)\n",
    "    return df\n",
    "\n",
    "df_numeric = remove_skewness(df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b07b88-074d-47a3-a13a-1eff47cfbc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skewness of Numerical Features :\n",
      "age                                          0.374340\n",
      "industry code                                0.509157\n",
      "occupation code                              0.822679\n",
      "enrolled in edu last week                    0.000000\n",
      "capital losses                               0.000000\n",
      "dividends from stocks                        0.000000\n",
      "tax filer status                             0.000000\n",
      "migration code-change in msa                 0.608011\n",
      "family members under 18                      0.742695\n",
      "fill inc questionaire for veteran's admin    0.000000\n",
      "weeks worked in year                         0.000000\n",
      "income                                       0.204515\n",
      "wage per hour                               -0.002365\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute skewness \n",
    "print(\"\\nSkewness of Numerical Features :\")\n",
    "print(df_numeric.skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258ece49-f9ef-4917-8d9d-831c2902b9f1",
   "metadata": {},
   "source": [
    "## EXPLORATORY DATA ANALYSIS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cea4e6-8210-4983-810f-cee0ef472af6",
   "metadata": {},
   "source": [
    "The dataset contains a mix of numerical and categorical variables.\n",
    "Some numerical columns, such as capital losses, dividends from stocks, and tax filer status, have extreme values, suggesting potential outliers.\n",
    "Age ranges from 0 to 90, with a mean of 34 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89573456-3864-4d75-b5ba-64c3346589a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for numerical features\n",
    "df.hist(figsize=(12, 8), bins=30)\n",
    "plt.suptitle(\"Histograms of Numerical Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a442407-b79c-4687-a7b3-831f6d0a0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_numeric = df.select_dtypes(include=['number']).dropna()\n",
    "if not df_numeric.empty:\n",
    "    sns.heatmap(df_numeric.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numeric columns available for correlation heatmap.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc88af-215f-469a-bb1d-67357d567b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for numerical features (sampled to avoid performance issues if dataset is large)\n",
    "sns.pairplot(df.sample(min(500, len(df))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0dbe86-1cb0-40c3-af04-24a39c690906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"EDA Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f0c11ea-37d2-4012-962a-fa8dc61751e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57c0845-ac9e-4f41-9cd1-594cc7d63088",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec8e582f-aa7a-4ef9-8c26-f0ae76c024b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc25fe-7ece-4dfa-97aa-e30865827edb",
   "metadata": {},
   "source": [
    "### Splitting dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92c5bc21-4cd2-40ed-aa6e-3d72e55fa6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('income', axis=1)\n",
    "y = df['income']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4c77261-afdf-4734-a3d0-55d0bdc6ac10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset split into training and testing sets.\n",
      "Training set size: (33827, 6)\n",
      "Testing set size: (8457, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"\\nDataset split into training and testing sets.\")\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fc5662-0747-4b70-9dd8-94c3adb0f197",
   "metadata": {},
   "source": [
    "### Feature selection using SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc0886-3c58-4c8a-a385-5e7615e1d80f",
   "metadata": {},
   "source": [
    "Feature selection is the process of choosing the most relevant features from a dataset to improve model performance, reduce overfitting, and enhance interpretability. It helps in dimensionality reduction, making models more efficient and faster.\n",
    "\n",
    "1. SelectKBest: SelectKBest is a feature selection method in scikit-learn that selects the top k features based on their scores using a specified statistical test. It helps improve model performance by removing irrelevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b779da9-2add-464d-b6ce-92c88321df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "if 'income' in df.columns:\n",
    "    X = df_numeric.drop(columns=['income'], errors='ignore')\n",
    "    y = df['income']\n",
    "    \n",
    "\n",
    "    X = X.loc[:, X.nunique() > 1]\n",
    "    \n",
    "   \n",
    "    X, y = X.align(y, join='inner', axis=0)\n",
    "    \n",
    "    selector = SelectKBest(score_func=f_classif, k=min(5, X.shape[1]))  # Adjust k to available features\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "    print(\"\\nTop selected features:\", selected_features.tolist())\n",
    "else:\n",
    "    print(\"\\nFeature selection skipped: 'income' column not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66cd6287-517b-4781-8dc1-5397d0c2ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores:\n",
      "age: 0.380\n",
      "industry code: 0.539\n",
      "occupation code: 0.548\n",
      "migration code-change in msa: 0.025\n",
      "family members under 18: 0.695\n",
      "wage per hour: 0.003\n",
      "\n",
      "Top 12 Features:\n",
      "['family members under 18', 'occupation code', 'industry code', 'age', 'migration code-change in msa', 'wage per hour']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "# Calculate mutual information scores\n",
    "selector = SelectKBest(mutual_info_classif, k='all')\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Get mutual information scores\n",
    "mutual_info_scores = selector.scores_\n",
    "\n",
    "# Print mutual information scores\n",
    "print(\"Mutual Information Scores:\")\n",
    "for feature, score in zip(X_train.columns, mutual_info_scores):\n",
    "    print(f\"{feature}: {score:.3f}\")\n",
    "\n",
    "# Sort mutual information scores in descending order\n",
    "sorted_scores = sorted(zip(X_train.columns, mutual_info_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Select top 12 features\n",
    "top_12_features = [feature for feature, score in sorted_scores[:12]]\n",
    "\n",
    "print(\"\\nTop 12 Features:\")\n",
    "print(top_12_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f63c19-ea79-4145-94ed-c807f9aa1069",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a5571e9-3901-42ba-aaf7-8c4c1f376473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "scaler = StandardScaler() \n",
    "numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['income'])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c1b7c9-db03-4101-b5f9-0ccd8f998f66",
   "metadata": {},
   "source": [
    "### Machine Learning Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7ccac-3a6a-4dc9-b091-89dba8f338ea",
   "metadata": {},
   "source": [
    "Models\n",
    "Logistic Regression: Logistic Regression is a classification algorithm that predicts probabilities using the sigmoid function, making it ideal for binary classification tasks.\n",
    "\n",
    "Support Vector Machine(SVM): Support Vector Machine (SVM) is a classification algorithm that finds the optimal hyperplane to separate classes, maximizing the margin between them for better generalization.\n",
    "\n",
    "Random Forest: Random Forest is an ensemble learning algorithm that builds multiple decision trees and combines their outputs for more accurate and robust predictions, reducing overfitting.\n",
    "\n",
    "Decision Tre: Decision Tree is a supervised learning algorithm that splits data into branches based on feature conditions, forming a tree-like structure to make predictions.\n",
    "\n",
    "K-Nearest Neighbors: K-Nearest Neighbors (KNN) is a simple, non-parametric algorithm that classifies data points based on the majority class of their K closest neighbors.\n",
    "\n",
    "Gradient Boosting: Gradient Boosting is an ensemble method that combines multiple weak learners to form a strong predictive model. It efficiently captures complex feature interactions and handles large datasets but can be computationally intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63a677-d1a7-47ae-aac6-5c59596a1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_train_pred = model.predict(X_train_selected)\n",
    "    y_test_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
    "    print(f\"Testing Accuracy: {test_accuracy:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0002ec7e-30ba-4477-8fe3-9e0b8eed8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Model': ['Logistic Regression', 'Support Vector Machine', 'Random Forest', 'Decision Tree', 'K-Nearest Neighbors', 'Gradient Boosting'],\n",
    "        'Training Accuracy': [0.584, 0.614, 0.978, 0.978,0.832,0.742],\n",
    "        'Testing Accuracy': [0.579, 0.622, 0.846, 0.741, 0.751, 0.720 ]}\n",
    "df_data = pd.DataFrame(data)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e8591-6251-4beb-a490-6d006a910de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(penalty='l2', solver='lbfgs', max_iter=500),\n",
    "    \"Support Vector Machine\": SVC(kernel='linear', C=0.1),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=50, max_features='sqrt', max_depth=10),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(ccp_alpha=0.001, max_depth=10, min_samples_split=10),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=10),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, learning_rate=0.05)\n",
    "}\n",
    "\n",
    "# Apply regularization and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    # Printing the results\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"Train_Accuracy: {train_accuracy}\")\n",
    "    print(f\"Test_Accuracy: {test_accuracy}\")\n",
    "    print()new_data = {\n",
    "    'Model': ['Logistic Regression', 'Support Vector Machine', 'Random Forest', \n",
    "              'Decision Tree', 'K-Nearest Neighbors', 'Gradient Boosting'],\n",
    "    'Previous Training Accuracy': [0.584, 0.614, 0.978, 0.978,0.832,0.742],\n",
    "    'Regularized Training Accuracy': [0.6183193086195133, 0.614623607004776, 0.8566067773481919, \n",
    "                                      0.7221400955196725, 0.7953149874914714, 0.7751876279281328],\n",
    "    'Previous Testing Accuracy': [0.579, 0.622, 0.846, 0.741, 0.751, 0.720 ],\n",
    "    'Regularized Testing Accuracy': [0.6139154160982264, 0.6139154160982264, 0.7762619372442019,  \n",
    "                                     0.7007730786721237, 0.7312414733969986, 0.7526148249204184]\n",
    "}\n",
    "df_new_data = pd.DataFrame(new_data)\n",
    "df_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d9300-ee99-494f-b571-3cbb77d5d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"F1-score: {f1_score(y_test, y_pred)}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85643aa-3b08-4472-92f9-468ce1be36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comparison = {\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\", \"Support Vector Machine\", \"Random Forest\",\n",
    "        \"Decision Tree\", \"K-Nearest Neighbors\", \"Gradient Boosting\"\n",
    "    ],\n",
    "    \"Accuracy\": [0.6139154160982264, 0.6139154160982264, 0.7748976807639836, \n",
    "                 0.7007730786721237, 0.7312414733969986, 0.7526148249204184],\n",
    "    \"Precision\": [0.6097145291861952, 0.6086039645719106, 0.7763217352010845, \n",
    "                  0.6967968407196139, 0.6951912154486937, 0.7537212449255751],\n",
    "    \"Recall\": [0.6466335291459557, 0.6520560325350203, 0.7763217352010845, \n",
    "               0.7175779484862178, 0.8296430185268866, 0.755083596927248],\n",
    "    \"F1-score\": [0.6276315789473684, 0.6295811518324608, 0.7763217352010845, \n",
    "                 0.7070347284060552, 0.7564894932014833, 0.7544018058690746]\n",
    "}\n",
    "df_comparison = pd.DataFrame(comparison)\n",
    "df_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1e906-719a-4b3c-aa2e-4b4a5777844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison.sort_values(by=['Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2290aa93-ccf7-4c8e-acfe-4fad23227f8a",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2433b-32bc-4bf1-998d-e026006bf66e",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is the process of selecting the best set of hyperparameters to optimize a machine learning model's performance. Unlike model parameters (learned from data), hyperparameters are set manually before training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e651272-1a65-4328-ac67-4d539f8392b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def8dba-de88-4711-9051-d36e263d88b9",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic (ROC) Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07928e47-6cb8-4151-9faa-5dd0e2775eb8",
   "metadata": {},
   "source": [
    "The ROC Curve is a graphical representation that evaluates the performance of a classification model by plotting the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f49cc-8d5c-4317-92a0-8130097ba15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Plot ROC Curve for all models\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Ensure SVC models have probability enabled\n",
    "    if hasattr(model, \"predict_proba\"):  \n",
    "        y_prob = model.predict_proba(X_test)[:, 1] \n",
    "    else:\n",
    "        continue  \n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)  \n",
    "    roc_auc = auc(fpr, tpr)  \n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "# Plotting aesthetics\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label=\"Random Guessing\")  \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f5721-352e-4ff5-8cae-87cb43159a02",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d13ed-6f84-4b2d-ab45-b648f4da74e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_rf, \"random_forest_model.pkl\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a73508-1ea0-4410-acc7-ed2202951715",
   "metadata": {},
   "source": [
    "### Pipeline for ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62782907-87d5-4adf-a713-51f87ec2174e",
   "metadata": {},
   "source": [
    "A machine learning pipeline is to automate data preprocessing, feature selection, and model training, ensuring efficiency and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f3e2d-fa01-417c-bc71-de7e08ffa96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = ImbPipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')), \n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('feature_selection', SelectKBest(mutual_info_classif, k=12)),  \n",
    "    ('smote', SMOTE(random_state=42)), \n",
    "    ('classifier', RandomForestClassifier(n_estimators=300, max_depth=None, random_state=42))  \n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72618cb1-b982-4c44-afb3-bb8b1008592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipe, 'pipeline.joblib')\n",
    "print(\"Pipeline saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
